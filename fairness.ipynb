{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import randint\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, cross_validate, cross_val_predict, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, roc_auc_score, make_scorer, SCORERS, confusion_matrix, roc_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"C:/Users/s1027177/OneDrive - Syngenta/Documents/BigData/Class8\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Read the file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Treat6m</th>\n",
       "      <th>Naive</th>\n",
       "      <th>EMRA</th>\n",
       "      <th>CM</th>\n",
       "      <th>EM</th>\n",
       "      <th>CD11a</th>\n",
       "      <th>CXCR3</th>\n",
       "      <th>CCR5</th>\n",
       "      <th>CXCR4</th>\n",
       "      <th>CXCR5</th>\n",
       "      <th>...</th>\n",
       "      <th>GzB</th>\n",
       "      <th>GzA</th>\n",
       "      <th>CD127</th>\n",
       "      <th>CD58</th>\n",
       "      <th>GAL-3</th>\n",
       "      <th>CD5</th>\n",
       "      <th>ICAM-1</th>\n",
       "      <th>CD38</th>\n",
       "      <th>CCR4</th>\n",
       "      <th>CTLA-4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0304</td>\n",
       "      <td>0.260</td>\n",
       "      <td>0.0150</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>0.9346</td>\n",
       "      <td>0.775552</td>\n",
       "      <td>0.070052</td>\n",
       "      <td>0.339160</td>\n",
       "      <td>0.546893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781068</td>\n",
       "      <td>0.901904</td>\n",
       "      <td>0.200926</td>\n",
       "      <td>0.476314</td>\n",
       "      <td>0.818068</td>\n",
       "      <td>0.946954</td>\n",
       "      <td>0.990000</td>\n",
       "      <td>0.262730</td>\n",
       "      <td>0.270001</td>\n",
       "      <td>0.163433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.1560</td>\n",
       "      <td>0.269</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.0832</td>\n",
       "      <td>0.7110</td>\n",
       "      <td>0.812970</td>\n",
       "      <td>0.273710</td>\n",
       "      <td>0.375861</td>\n",
       "      <td>0.361873</td>\n",
       "      <td>...</td>\n",
       "      <td>0.425790</td>\n",
       "      <td>0.544353</td>\n",
       "      <td>0.053836</td>\n",
       "      <td>0.580217</td>\n",
       "      <td>0.469866</td>\n",
       "      <td>0.998994</td>\n",
       "      <td>0.997190</td>\n",
       "      <td>0.145660</td>\n",
       "      <td>0.321924</td>\n",
       "      <td>0.041356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.0363</td>\n",
       "      <td>0.2940</td>\n",
       "      <td>0.8970</td>\n",
       "      <td>0.539334</td>\n",
       "      <td>0.070597</td>\n",
       "      <td>0.162852</td>\n",
       "      <td>0.195341</td>\n",
       "      <td>...</td>\n",
       "      <td>0.780501</td>\n",
       "      <td>0.932139</td>\n",
       "      <td>0.321604</td>\n",
       "      <td>0.484588</td>\n",
       "      <td>0.762041</td>\n",
       "      <td>0.993183</td>\n",
       "      <td>0.997586</td>\n",
       "      <td>0.385564</td>\n",
       "      <td>0.249591</td>\n",
       "      <td>0.062653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0283</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.9861</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.169069</td>\n",
       "      <td>0.199353</td>\n",
       "      <td>0.307644</td>\n",
       "      <td>...</td>\n",
       "      <td>0.864433</td>\n",
       "      <td>0.987819</td>\n",
       "      <td>0.382722</td>\n",
       "      <td>0.602925</td>\n",
       "      <td>0.645262</td>\n",
       "      <td>0.988252</td>\n",
       "      <td>0.999200</td>\n",
       "      <td>0.170346</td>\n",
       "      <td>0.400480</td>\n",
       "      <td>0.067871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0653</td>\n",
       "      <td>0.216</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.2040</td>\n",
       "      <td>0.9209</td>\n",
       "      <td>0.847934</td>\n",
       "      <td>0.245060</td>\n",
       "      <td>0.182395</td>\n",
       "      <td>0.174046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.609748</td>\n",
       "      <td>0.932809</td>\n",
       "      <td>0.373745</td>\n",
       "      <td>0.340299</td>\n",
       "      <td>0.102806</td>\n",
       "      <td>0.980924</td>\n",
       "      <td>0.996289</td>\n",
       "      <td>0.148594</td>\n",
       "      <td>0.156187</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Treat6m   Naive   EMRA      CM      EM   CD11a     CXCR3      CCR5  \\\n",
       "0        1  0.0304  0.260  0.0150  0.2580  0.9346  0.775552  0.070052   \n",
       "1        0  0.1560  0.269  0.0387  0.0832  0.7110  0.812970  0.273710   \n",
       "2        1  0.0646  0.211  0.0363  0.2940  0.8970  0.539334  0.070597   \n",
       "3        0  0.0283  0.240  0.1180  0.1300  0.9861  0.857143  0.169069   \n",
       "4        0  0.0653  0.216  0.0949  0.2040  0.9209  0.847934  0.245060   \n",
       "\n",
       "      CXCR4     CXCR5  ...       GzB       GzA     CD127      CD58     GAL-3  \\\n",
       "0  0.339160  0.546893  ...  0.781068  0.901904  0.200926  0.476314  0.818068   \n",
       "1  0.375861  0.361873  ...  0.425790  0.544353  0.053836  0.580217  0.469866   \n",
       "2  0.162852  0.195341  ...  0.780501  0.932139  0.321604  0.484588  0.762041   \n",
       "3  0.199353  0.307644  ...  0.864433  0.987819  0.382722  0.602925  0.645262   \n",
       "4  0.182395  0.174046  ...  0.609748  0.932809  0.373745  0.340299  0.102806   \n",
       "\n",
       "        CD5    ICAM-1      CD38      CCR4    CTLA-4  \n",
       "0  0.946954  0.990000  0.262730  0.270001  0.163433  \n",
       "1  0.998994  0.997190  0.145660  0.321924  0.041356  \n",
       "2  0.993183  0.997586  0.385564  0.249591  0.062653  \n",
       "3  0.988252  0.999200  0.170346  0.400480  0.067871  \n",
       "4  0.980924  0.996289  0.148594  0.156187  0.000000  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cll dataset\n",
    "datafile = \"cll_dataset.csv\"\n",
    "cll = pd.read_csv(datafile, sep=\",\")\n",
    "cll.head()\n",
    "# a row is a sample = a patient\n",
    "# column 'Treat6m' recurrence of the disease, 1 if true, 0 if false\n",
    "# other columns are features = rate of several types of cells and molecules in the patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    24\n",
       "1     7\n",
       "Name: Treat6m, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(cll[\"Treat6m\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Create X the features, Y the predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = cll[\"Treat6m\"]\n",
    "X = cll.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.**\n",
    "* Create a function 'fit_rf' that fit random forests on xtrain, ytrain\n",
    "* It should return the random forest score on the xtest, ytest set.\n",
    "* Use sklearn implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_rf(X, Y, seed, test_size):\n",
    "    \n",
    "    '''\n",
    "      Split the dataset into test and train set. Fit a Random Forest and compute the score.\n",
    "\n",
    "      Parameters \n",
    "      ----------\n",
    "      X: array \n",
    "        Values of all the features/predictors\n",
    "      Y: array \n",
    "        Values of the target variable\n",
    "      test_size: float \n",
    "        Proportion of the dataset to include in the test split\n",
    "      seed: int\n",
    "        Controls the random_state parameter in sklearn RandomForestClassifier \n",
    "\n",
    "      Returns\n",
    "      -------\n",
    "      Accuracy of the prediction\n",
    "      \n",
    "    '''\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, stratify=Y)\n",
    "    \n",
    "    rf = RandomForestClassifier(random_state=seed)\n",
    "    rf.fit(x_train, y_train)\n",
    "    score = rf.score(x_test,y_test)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.**\n",
    "* Create a function 'repeat_experiment' that will re-shuffle the dataset and fit a classifier a hundred times\n",
    "* Store the score at each iteration\n",
    "* Return the average score on the hundred iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def repeat_experiment(X, Y, seed, test_size=0.2, B=100):\n",
    "    \n",
    "    '''\n",
    "    Re-shuffle the dataset and fit a classifier B times. Get the average score on the B iterations.\n",
    "\n",
    "        Parameters \n",
    "        ----------\n",
    "        X: array \n",
    "            Values of all the features/predictors\n",
    "        Y: array \n",
    "            Values of the target variable\n",
    "        test_size: float \n",
    "            Proportion of the dataset to include in the test split\n",
    "        seed: int\n",
    "            Controls the random_state parameter in sklearn RandomForestClassifier \n",
    "        B: int\n",
    "            Number of iterations\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Average accuracy on the B predictions\n",
    "\n",
    "    '''\n",
    "    scores = []\n",
    "    \n",
    "    while len(scores) < B:\n",
    "        scores.append(fit_rf(X, Y, seed, test_size))\n",
    "        \n",
    "    return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. Is it good (check score averaged over a hundred experiments)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score over a hundred experiments is: 0.70\n"
     ]
    }
   ],
   "source": [
    "print(\"The average score over a hundred experiments is: %.2f\" %  repeat_experiment(X, Y, seed=seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy is high. It seems quite good at first sight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. Is it actually good ? Try to predict only vectors with 'Treat6m' = 1. You can compute per-class precision, recall, f-scores...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_class_fit(X, Y, seed, target_class=1, test_size=0.2, B=100):\n",
    "    \n",
    "    '''\n",
    "    Re-shuffle the dataset and fit a classifier B times. Get the average score on the B iterations for only one class.\n",
    "\n",
    "        Parameters \n",
    "        ----------\n",
    "        X: array \n",
    "            Values of all the features/predictors\n",
    "        Y: array \n",
    "            Values of the target variable\n",
    "        target_class: int\n",
    "            Category of the binary variable for which to predict\n",
    "        test_size: float \n",
    "            Proportion of the dataset to include in the test split\n",
    "        seed: int\n",
    "            Controls the random_state parameter in sklearn RandomForestClassifier \n",
    "        B: int\n",
    "            Number of iterations\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Average accuracy on the B predictions for the class specified.\n",
    "\n",
    "    '''  \n",
    "    scores = []\n",
    "    \n",
    "    while len(scores) < B:\n",
    "        \n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, stratify=Y)\n",
    "    \n",
    "        rf = RandomForestClassifier(random_state=seed)\n",
    "        rf.fit(x_train, y_train)\n",
    "        \n",
    "        x_test_ = x_test[y_test==target_class]\n",
    "        y_test_ = y_test[y_test==target_class]\n",
    "        \n",
    "        if len(x_test_) > 0 :\n",
    "            score = rf.score(x_test_, y_test_) \n",
    "            scores.append(score)\n",
    "\n",
    "    return sum(scores)/len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average score for sick patients is: 0.00\n"
     ]
    }
   ],
   "source": [
    "print(\"The average score for sick patients is: %.2f\" % one_class_fit(X, Y, seed=seed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering on patients having `'Treat6m' = 1`, the prediction is clearly bad. Accuracy drops to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores(X, Y, seed, target_class=1, test_size=0.2, B=100):\n",
    "    \n",
    "    '''\n",
    "    Re-shuffle the dataset and fit a classifier B times. Get the average recall, precision and F-score\n",
    "    on the B iterations for only one class.\n",
    "\n",
    "        Parameters \n",
    "        ----------\n",
    "        X: array \n",
    "            Values of all the features/predictors\n",
    "        Y: array \n",
    "            Values of the target variable\n",
    "        target_class: int\n",
    "            Category of the binary variable for which to predict\n",
    "        test_size: float \n",
    "            Proportion of the dataset to include in the test split\n",
    "        seed: int\n",
    "            Controls the random_state parameter in sklearn RandomForestClassifier \n",
    "        B: int\n",
    "            Number of iterations\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Average recall, precision, and F-score on the B predictions for the class specified.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    accuracy = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    f1score = []\n",
    "\n",
    "    while len(recall) < B:\n",
    "    \n",
    "        x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=test_size)\n",
    "\n",
    "        rf = RandomForestClassifier(random_state=seed)\n",
    "        rf.fit(x_train, y_train)\n",
    "\n",
    "        x_test_ = x_test[y_test==target_class]\n",
    "        y_test_ = y_test[y_test==target_class]\n",
    "\n",
    "        if len(x_test_) > 0:\n",
    "\n",
    "            # Get the vectors of y-true and y-predicted\n",
    "            y_true = np.array(y_test_)\n",
    "            y_pred = rf.predict(x_test_)\n",
    "\n",
    "            # Get the classification report \n",
    "            dico = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "\n",
    "            # Store the different scores\n",
    "            accuracy.append(dico['accuracy'])\n",
    "            recall.append(dico[str(target_class)]['recall'])\n",
    "            precision.append(dico[str(target_class)]['precision'])\n",
    "            f1score.append(dico[str(target_class)]['f1-score'])\n",
    "\n",
    "    # Get the averages of those scores \n",
    "    sc = {'Accuracy': [sum(accuracy)/len(accuracy)],\n",
    "          'Recall': [sum(recall)/len(recall)],\n",
    "          'Precision': [sum(precision)/len(precision)],\n",
    "          'F-score': [sum(f1score)/len(f1score)]}\n",
    "    scores = pd.DataFrame(sc)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "Classification metrics for Y=1: \n",
      "   Accuracy  Recall  Precision   F-score\n",
      "0     0.005   0.005       0.01  0.006667\n",
      "-------------\n",
      "Classification metrics for Y=0: \n",
      "   Accuracy   Recall  Precision   F-score\n",
      "0   0.97231  0.97231        1.0  0.984811\n"
     ]
    }
   ],
   "source": [
    "print(\"-------------\")\n",
    "print(\"Classification metrics for Y=1: \")\n",
    "print(scores(X, Y, seed=seed, target_class=1))\n",
    "\n",
    "print(\"-------------\")\n",
    "print(\"Classification metrics for Y=0: \")\n",
    "print(scores(X, Y, seed=seed, target_class=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Why is it actually pretty bad ?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset used for training is clearly imbalanced in favor of class 0. Then it predicts zero most of the time. The classifier is good when it comes to predict healthy patients, the accuracy reaches 0.98. But it is really bad for detecting sick patients because of the imbalanceness of the dataset. The data is not sufficient for training the model, there are too few patients with `Treat6m = 1`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**0. Load the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender dataset\n",
    "genderdatafile = \"gender_biased.csv\"\n",
    "jobs = pd.read_csv(genderdatafile, sep=\",\", index_col=0)\n",
    "# Amazon has recorded some data from its job interviews.\n",
    "# After compiling all the data,\n",
    "# they came with a pair of features called \"skills\" and \"human fit\"\n",
    "# that are supposed to be sufficient to predict whether a candidate is worth interviewing.\n",
    "target = \"selected\"\n",
    "sensitive = \"gender\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skills</th>\n",
       "      <th>human_fit</th>\n",
       "      <th>gender</th>\n",
       "      <th>selected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-6.160503</td>\n",
       "      <td>-3.266742</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.951289</td>\n",
       "      <td>-4.117315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.255315</td>\n",
       "      <td>2.801389</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.440054</td>\n",
       "      <td>-3.465629</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.338412</td>\n",
       "      <td>-0.334471</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     skills  human_fit  gender  selected\n",
       "0 -6.160503  -3.266742       1         0\n",
       "1  1.951289  -4.117315       0         0\n",
       "2  2.255315   2.801389       1         1\n",
       "3 -7.440054  -3.465629       0         0\n",
       "4  0.338412  -0.334471       0         1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jobs.gender = jobs.gender.astype(int)\n",
    "jobs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>selected</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>719</td>\n",
       "      <td>359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>281</td>\n",
       "      <td>641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "selected    0    1\n",
       "gender            \n",
       "0         719  359\n",
       "1         281  641"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(jobs.gender, jobs.selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Which feature should not be taken into account to discriminate candidates ?**\n",
    "\n",
    "Gender should not be used to discrimate candidates. We should not consider the effect of the gender on the professional skills as causal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2. Fit classifiers of your choice on the given dataset (output is \"selected\" column) do not use the \"sensitive\" feature!!!** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(df, seed, target=target, sensitive=sensitive, test_size=0.3):\n",
    "    \n",
    "    Y = df[target]\n",
    "    X = df.drop(target, axis=1)\n",
    "    \n",
    "    return train_test_split(X, Y, test_size=test_size, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gb_clf(X, Y, seed, include_sensitive=False, sample_weight=None):\n",
    "\n",
    "    gb = GradientBoostingClassifier(random_state=seed)\n",
    "    if include_sensitive:\n",
    "        gb.fit(X, Y, sample_weight=sample_weight)\n",
    "    else: \n",
    "        gb.fit(X.drop(sensitive, axis=1), Y, sample_weight=sample_weight)\n",
    "    \n",
    "    return gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating 100 times the experiment\n",
    "def scores_repeated_exper(df, target=target, test_size=0.3, sensitive=sensitive, include_sensitive=False, B=100):\n",
    "    \n",
    "    accuracy = []\n",
    "    recall = []\n",
    "    precision = []\n",
    "    f1score = []\n",
    "\n",
    "    while len(accuracy) < B:\n",
    "        \n",
    "        seed = randint(1,1000)\n",
    "        X_train, X_test, y_train, y_test = split_dataset(df, seed=seed, target=target,\n",
    "                                                         sensitive=sensitive, test_size=test_size)\n",
    "        \n",
    "        gb = fit_gb_clf(X_train, y_train, seed=seed,\n",
    "                        include_sensitive=include_sensitive)\n",
    "        \n",
    "        if include_sensitive:\n",
    "            y_pred = gb.predict(X_test)\n",
    "        else: \n",
    "            y_pred = gb.predict(X_test.drop(sensitive, axis = 1))\n",
    "\n",
    "        # Store the different scores\n",
    "        accuracy.append(accuracy_score(y_test, y_pred))\n",
    "        recall.append(recall_score(y_test, y_pred))\n",
    "        precision.append(precision_score(y_test, y_pred))\n",
    "        f1score.append(f1_score(y_test, y_pred))\n",
    "\n",
    "    # Get the averages of those scores \n",
    "    sc = {'Accuracy': [sum(accuracy)/len(accuracy)],\n",
    "          'Recall': [sum(recall)/len(recall)],\n",
    "          'Precision': [sum(precision)/len(precision)],\n",
    "          'F1-score': [sum(f1score)/len(f1score)]\n",
    "         }\n",
    "    scores = pd.DataFrame(sc)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['explained_variance', 'r2', 'max_error', 'neg_median_absolute_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error', 'neg_mean_squared_error', 'neg_mean_squared_log_error', 'neg_root_mean_squared_error', 'neg_mean_poisson_deviance', 'neg_mean_gamma_deviance', 'accuracy', 'top_k_accuracy', 'roc_auc', 'roc_auc_ovr', 'roc_auc_ovo', 'roc_auc_ovr_weighted', 'roc_auc_ovo_weighted', 'balanced_accuracy', 'average_precision', 'neg_log_loss', 'neg_brier_score', 'adjusted_rand_score', 'rand_score', 'homogeneity_score', 'completeness_score', 'v_measure_score', 'mutual_info_score', 'adjusted_mutual_info_score', 'normalized_mutual_info_score', 'fowlkes_mallows_score', 'precision', 'precision_macro', 'precision_micro', 'precision_samples', 'precision_weighted', 'recall', 'recall_macro', 'recall_micro', 'recall_samples', 'recall_weighted', 'f1', 'f1_macro', 'f1_micro', 'f1_samples', 'f1_weighted', 'jaccard', 'jaccard_macro', 'jaccard_micro', 'jaccard_samples', 'jaccard_weighted'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SCORERS.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing cross-validation\n",
    "def fit_cv_gb(X, Y, seed, n_splits=5, n_repeats=3, scoring=['accuracy', 'precision', 'recall', 'f1']):\n",
    "\n",
    "    gb = GradientBoostingClassifier(random_state=seed)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=seed)\n",
    "    n_scores = cross_validate(gb, X, Y, scoring=scoring, cv=cv, error_score='raise')\n",
    "    \n",
    "    sc = {'Accuracy': [np.mean(n_scores['test_accuracy'])],\n",
    "          'Recall': [np.mean(n_scores['test_recall'])],\n",
    "          'Precision': [np.mean(n_scores['test_precision'])],\n",
    "          'F1-score': [np.mean(n_scores['test_f1'])]\n",
    "         }\n",
    "    scores = pd.DataFrame(sc)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same with another classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def fit_cv_svc(X, Y, seed, n_splits=5, n_repeats=3, scoring=['accuracy', 'precision', 'recall', 'f1']):\n",
    "\n",
    "    svc = SVC(random_state=seed)\n",
    "    cv = RepeatedStratifiedKFold(n_splits=n_splits, n_repeats=n_repeats, random_state=seed)\n",
    "    n_scores = cross_validate(svc, X, Y, scoring=scoring, cv=cv, error_score='raise')\n",
    "\n",
    "    sc = {'Accuracy': [np.mean(n_scores['test_accuracy'])],\n",
    "          'Recall': [np.mean(n_scores['test_recall'])],\n",
    "          'Precision': [np.mean(n_scores['test_precision'])],\n",
    "          'F1-score': [np.mean(n_scores['test_f1'])]\n",
    "         }\n",
    "    scores = pd.DataFrame(sc)\n",
    "\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3. Evaluate the classifiers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.862433</td>\n",
       "      <td>0.858161</td>\n",
       "      <td>0.865247</td>\n",
       "      <td>0.861349</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy    Recall  Precision  F1-score\n",
       "0  0.862433  0.858161   0.865247  0.861349"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_repeated_exper(jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.859667</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.867413</td>\n",
       "      <td>0.858255</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision  F1-score\n",
       "0  0.859667    0.85   0.867413  0.858255"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = jobs[target]\n",
    "X = jobs.drop(labels=[target,sensitive], axis=1)\n",
    "fit_cv_gb(X, Y, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Precision</th>\n",
       "      <th>F1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.8685</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.875359</td>\n",
       "      <td>0.867393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  Recall  Precision  F1-score\n",
       "0    0.8685    0.86   0.875359  0.867393"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit_cv_svc(X, Y, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All scores are above 80%. The SVM classifier performs slightly better than the gradient boosting. We will use this classifier for the next steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_svc_clf(X, y, seed, include_sensitive=False, sample_weight=None):\n",
    "\n",
    "    svc = SVC(random_state=seed)\n",
    "    if include_sensitive:\n",
    "        svc.fit(X, y, sample_weight=sample_weight)\n",
    "    else: \n",
    "        svc.fit(X.drop(sensitive, axis=1), y, sample_weight=sample_weight)\n",
    "    \n",
    "    return svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_test, y_pred):\n",
    "\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred, average='macro')\n",
    "    precision = precision_score(y_test, y_pred, average='macro')\n",
    "    f1score = f1_score(y_test, y_pred, average='macro')\n",
    "    \n",
    "    metrics = {'Accuracy': [accuracy],\n",
    "               'Recall': [recall],\n",
    "               'Precision': [precision],\n",
    "               'F1-score': [f1score]\n",
    "              }\n",
    "    \n",
    "    metrics = pd.DataFrame(metrics)\n",
    "    \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4. What is the impact of automatic decision on the \"protected group\" (the one with sensitive=1)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to know how well our model treats different individuals wrt their gender. We could use the demographic parity as a measure of fairness. It states that the proportion of each segment of a protected class, e.g. gender, should receive the positive outcome (being selected for an job interview) at equal rates. Mathematically, it can be formalized by:\n",
    "$\\hat{P}(\\hat{Y}=1 | G=1) \\stackrel{?}{=} \\hat{P}(\\hat{Y}=1 | G=0))$. Another interesting measure to consider would be $\\hat{P}(\\hat{Y}=1 | Y=1, G=1) \\stackrel{?}{=} \\hat{P}(\\hat{Y}=1 | Y=1, G=0))$. If the equality holds, it is called equal opportunity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cond_proba(y_test, y_pred, sensitive_col, positive_target=1):\n",
    "    \n",
    "    # Compute the probability of a positive outcome given sensitive being 1\n",
    "    # and the same probability given sensitive being 0\n",
    "    y_given_g1 = y_pred[sensitive_col == 1]\n",
    "    y_given_g0 = y_pred[sensitive_col == 0]\n",
    "    p_g1 = np.mean(y_given_g1 == positive_target)\n",
    "    p_g0 = np.mean(y_given_g0 == positive_target)\n",
    "    \n",
    "    if p_g1 == 0 or p_g0 == 0:\n",
    "        p_percent = 0 \n",
    "    else: \n",
    "        p_percent = np.minimum(p_g1 / p_g0, p_g0 / p_g1)\n",
    "    \n",
    "    # Compute the probability of a true positive outcome given sensitive being 1\n",
    "    # and the same probability given sensitive being 0\n",
    "    y_given_g1_y1 = y_pred[(sensitive_col == 1) & (y_test == positive_target)]\n",
    "    y_given_g0_y1 = y_pred[(sensitive_col == 0) & (y_test == positive_target)]\n",
    "    \n",
    "    if len(y_given_g1_y1) == 0 or len(y_given_g0_y1) == 0:\n",
    "        p_y1_g1 = 0\n",
    "        p_y1_g0 = 0\n",
    "    else:\n",
    "        p_y1_g1 = np.mean(y_given_g1_y1 == positive_target)\n",
    "        p_y1_g0 = np.mean(y_given_g0_y1 == positive_target)\n",
    "\n",
    "    score = np.minimum(p_y1_g1 / p_y1_g0, p_y1_g0 / p_y1_g1)\n",
    "\n",
    "    prob = {'p_g1': [p_g1],\n",
    "            'p_g0': [p_g0],\n",
    "            'p_percent': [p_percent],\n",
    "            'p_y1_g1': [p_y1_g1],\n",
    "            'p_y1_g0': [p_y1_g0],\n",
    "            'eq_opp_score': [score],\n",
    "           }\n",
    "    prob = pd.DataFrame(prob)\n",
    "    \n",
    "    return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating 100 times the experiment\n",
    "def evaluate_clf(df, target=target, test_size=0.3,\n",
    "                 sensitive=sensitive, positive_target=1,\n",
    "                 include_sensitive=False, weighted=False, B=100):\n",
    "    \n",
    "    pd_metrics = pd.DataFrame(columns=[\"Accuracy\", \"Recall\", \"Precision\", \"F1-score\"])\n",
    "    pd_prob = pd.DataFrame(columns=[\"p_g1\", \"p_g0\", \"p_percent\", \"p_y1_g1\", \"p_y1_g0\", \"eq_opp_score\"])\n",
    "\n",
    "    while pd_metrics.shape[0] < B:\n",
    "        \n",
    "        seed = randint(1,1000)        \n",
    "        X_train, X_test, y_train, y_test = split_dataset(df, seed=seed, target=target,\n",
    "                                                         sensitive=sensitive, test_size=test_size)\n",
    "        \n",
    "        if weighted:\n",
    "            svc = fit_svc_clf(X_train, y_train, seed=seed,\n",
    "                              include_sensitive=include_sensitive,\n",
    "                              sample_weight=weight_samples(X_train, y_train))           \n",
    "        else:\n",
    "            svc = fit_svc_clf(X_train, y_train, seed=seed,\n",
    "                              include_sensitive=include_sensitive)\n",
    "        \n",
    "        if include_sensitive:\n",
    "            y_pred = svc.predict(X_test)\n",
    "        else: \n",
    "            y_pred = svc.predict(X_test.drop(sensitive, axis = 1))\n",
    "        \n",
    "        metrics = compute_metrics(y_test, y_pred)\n",
    "        pd_metrics = pd.concat([pd_metrics, metrics])\n",
    "        \n",
    "        sensitive_col = X_test[sensitive]\n",
    "        prob = compute_cond_proba(y_test, y_pred, sensitive_col, positive_target)\n",
    "        pd_prob = pd.concat([pd_prob, prob])\n",
    "\n",
    "    print(\"Accuracy:\", pd_metrics[\"Accuracy\"].mean())\n",
    "    print(\"F1-score:\", pd_metrics[\"F1-score\"].mean()) \n",
    "    print(\"Precision score:\", pd_metrics[\"Precision\"].mean())\n",
    "    print(\"Recall score:\", pd_metrics[\"Recall\"].mean())\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"Demographic parity: \")\n",
    "    print(\"p_yhat1_given_g1:\", pd_prob[\"p_g1\"].mean())\n",
    "    print(\"p_yhat1_given_g0:\", pd_prob[\"p_g0\"].mean())\n",
    "    print(\"p% score:\", pd_prob[\"p_percent\"].mean())\n",
    "    print(\"-------------------\")\n",
    "    print(\"Equal opportunity: \")    \n",
    "    print(\"p_yhat1_given_y1_g1:\", pd_prob[\"p_y1_g1\"].mean())\n",
    "    print(\"p_yhat1_given_y1_g0:\", pd_prob[\"p_y1_g0\"].mean())\n",
    "    print(\"Equal opportunity score:\", pd_prob[\"eq_opp_score\"].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8709166666666667\n",
      "F1-score: 0.8707868303169789\n",
      "Precision score: 0.8711545368238772\n",
      "Recall score: 0.8709775907264214\n",
      "--------------------------------------\n",
      "Demographic parity: \n",
      "p_yhat1_given_g1: 0.7104913900472112\n",
      "p_yhat1_given_g0: 0.3021051079866779\n",
      "p% score: 0.4256374899355074\n",
      "-------------------\n",
      "Equal opportunity: \n",
      "p_yhat1_given_y1_g1: 0.9199605468956936\n",
      "p_yhat1_given_y1_g0: 0.7553364408299129\n",
      "Equal opportunity score: 0.8213479288366861\n"
     ]
    }
   ],
   "source": [
    "evaluate_clf(jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both measures show that our classifier is biased in favor of the group with gender being 1. The probability of being selected for an interview is much lower in the \"unprotected group\". The gap in probabilities is less important when `target = 1 ` is predicted correctly by the model but still remaining. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5. In sklearn, you can put a weight on samples. Find a weighting strategy to compute a fair classification.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a pre-processing technique, we can put different weights on samples in each group before classification. The weights for samples with $(G, Y)$ combination will be the product of the marginals over the joint. The idea is to have independence between $G$ and target $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_samples(X, Y, sensitive=sensitive):\n",
    "\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    sensitive_col = X[sensitive]\n",
    "    \n",
    "    p_g1 = X[sensitive_col == 1].shape[0] / n\n",
    "    p_g0 = X[sensitive_col == 0].shape[0] / n\n",
    "    p_y1 = Y[Y == 1].shape[0] / n\n",
    "    p_y0 = Y[Y == 0].shape[0] / n\n",
    "\n",
    "    p_g1_y1 = X[(sensitive_col == 1) & (Y == 1)].shape[0] / n\n",
    "    p_g0_y0 = X[(sensitive_col == 0) & (Y == 0)].shape[0] / n\n",
    "    p_g0_y1 = X[(sensitive_col == 0) & (Y == 1)].shape[0] / n\n",
    "    p_g1_y0 = X[(sensitive_col == 1) & (Y == 0)].shape[0] / n\n",
    "    \n",
    "    # Weights:\n",
    "    w1_1 = p_g1 * p_y1 / p_g1_y1\n",
    "    w0_0 = p_g0 * p_y0 / p_g0_y0\n",
    "    w0_1 = p_g0 * p_y1 / p_g0_y1\n",
    "    w1_0 = p_g1 * p_y0 / p_g1_y0\n",
    "\n",
    "    weights = np.where((sensitive_col == 1) & (Y == 1), w1_1,\n",
    "                       np.where((sensitive_col == 0) & (Y == 0), w0_0,\n",
    "                                np.where((sensitive_col == 1) & (Y == 0), w1_0,\n",
    "                                         np.where((sensitive_col == 0) & (Y == 1), w0_1, 0\n",
    "                                                 )\n",
    "                                        )\n",
    "                               )            \n",
    "                      )\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**6. Evaluate your classifier, check the trade-off between fairness and accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8604166666666666\n",
      "F1-score: 0.8602815379610772\n",
      "Precision score: 0.8608287314891172\n",
      "Recall score: 0.8604684493659919\n",
      "--------------------------------------\n",
      "Demographic parity: \n",
      "p_yhat1_given_g1: 0.6878591771670756\n",
      "p_yhat1_given_g0: 0.32017583867045524\n",
      "p% score: 0.46584223551790255\n",
      "-------------------\n",
      "Equal opportunity: \n",
      "p_yhat1_given_y1_g1: 0.8979791736388835\n",
      "p_yhat1_given_y1_g0: 0.7665234753365958\n",
      "Equal opportunity score: 0.8538098900902888\n"
     ]
    }
   ],
   "source": [
    "evaluate_clf(jobs, weighted=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this pre-processing technique, we gain a little bit in fairness. The probability of being selected for an interview slighly increases for the \"unprotected group\" and reversly for group with gender being 1. The accuracy of the model is not really affected. Surprisingly, using this approach still results in a biased model with a 47% p-score which is still much less than it should be in a fair classifier. We will have to find another strategy to increase the fairness scores while controlling the reduction in accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **7. Another strategy here would be post-processing train the classifier without re-weighting the samples.** \n",
    "* **8. Plot ROC curve for the \"protected group\" (sensitive=1)** \n",
    "* **9. On the same graph, plot the ROC curve for the \"unprotected group\" (sensitive=0)** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of post-processing algorithms is to derive a transformation of an existing classifier's prediction to apply specified impartiality constraints on the sensitive characteristic. Their simplicity and flexibility, as they do not need to reform the model are one of their advantages. We will perform the `ThresholdOptimizer` post-processing algorithm from the open-source python library `fairlearn`. It will help us to derive a monotonic transformation of the prediction of the previous SVC classifier applying a constraint on the demographic parity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics as skm\n",
    "import fairlearn\n",
    "from fairlearn.postprocessing import ThresholdOptimizer\n",
    "from fairlearn.metrics import MetricFrame\n",
    "from fairlearn.metrics import mean_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_roc_curve(estimator, X_test, A_test, y_test, base_fpr, sensitive=True):\n",
    "    \n",
    "    if sensitive:\n",
    "        index = A_test[A_test == 0].index\n",
    "        xtest = X_test.loc[index, :]\n",
    "        ytest = y_test.loc[index]\n",
    "    \n",
    "    else:\n",
    "        index = A_test[A_test == 1].index\n",
    "        xtest = X_test.loc[index, :]\n",
    "        ytest = y_test.loc[index]\n",
    "\n",
    "    ypred = estimator.predict(xtest, sensitive_features=A_test.loc[index])\n",
    "    # calculate roc curves\n",
    "    fpr, tpr, thresholds = roc_curve(ytest, ypred)\n",
    "    tpr = np.interp(base_fpr, fpr, tpr)\n",
    "    tpr[0] = 0.0\n",
    "    \n",
    "    return tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeating 100 times the experiment\n",
    "def evaluate_fairer_clf(df, constraint, target=target, test_size=0.3,\n",
    "                        sensitive=sensitive, positive_target=1,\n",
    "                        include_sensitive=False, B=100):\n",
    "    \n",
    "    X = df.drop(labels=[target,sensitive], axis=1)\n",
    "    y = df[target]\n",
    "    A = df[sensitive]\n",
    "    \n",
    "    pd_metrics = pd.DataFrame(columns=[\"Accuracy\", \"Recall\", \"Precision\", \"F1-score\"])\n",
    "    pd_prob = pd.DataFrame(columns=[\"p_g1\", \"p_g0\", \"p_percent\", \"p_y1_g1\", \"p_y1_g0\", \"eq_opp_score\"])\n",
    "    \n",
    "    tprs_unprotected = []\n",
    "    tprs_protected = []\n",
    "    base_fpr = np.linspace(0, 1, 101)\n",
    "    plt.figure(figsize=(5, 5))\n",
    "\n",
    "    while pd_metrics.shape[0] < B:\n",
    "\n",
    "        # Split into test and train, making sure we have sequential indices in the results\n",
    "        seed = randint(1,1000)    \n",
    "        X_train, X_test, y_train, y_test, A_train, A_test = train_test_split(X, y, A,\n",
    "                                                                             test_size=test_size,\n",
    "                                                                             random_state=seed)\n",
    "\n",
    "        X_train = X_train.reset_index(drop=True)\n",
    "        y_train = y_train.reset_index(drop=True)\n",
    "        A_train = A_train.reset_index(drop=True)\n",
    "        X_test = X_test.reset_index(drop=True)\n",
    "        y_test = y_test.reset_index(drop=True)\n",
    "        A_test = A_test.reset_index(drop=True)\n",
    "\n",
    "        y0 = y_train[y_train==positive_target-1]\n",
    "        y1 = y_train[y_train==positive_target]\n",
    "        \n",
    "        if len(y1) > len(y0):\n",
    "            balanced_index_pass0 = y_train[y_train==positive_target-1].index \n",
    "            balanced_index_pass1 = y_train[y_train==positive_target].sample(n=balanced_index_pass0.size,\n",
    "                                                                            random_state=seed).index\n",
    "            balanced_index = balanced_index_pass0.union(balanced_index_pass1)\n",
    "        else:\n",
    "            balanced_index_pass1 = y_train[y_train==positive_target].index \n",
    "            balanced_index_pass0 = y_train[y_train==positive_target-1].sample(n=balanced_index_pass1.size,\n",
    "                                                                              random_state=seed).index\n",
    "            balanced_index = balanced_index_pass1.union(balanced_index_pass0)\n",
    "        \n",
    "        unmitigated_predictor = SVC(random_state=seed)\n",
    "        unmitigated_predictor.fit(X_train, y_train)\n",
    "\n",
    "        pp_estimator = ThresholdOptimizer(estimator=unmitigated_predictor,\n",
    "                                          constraints=constraint,\n",
    "                                          prefit=True)\n",
    "        \n",
    "        pp_estimator.fit(X_train.iloc[balanced_index,:], y_train.iloc[balanced_index],\n",
    "                         sensitive_features=A_train.iloc[balanced_index])\n",
    "        \n",
    "        y_pred = pp_estimator.predict(X_test, sensitive_features=A_test)\n",
    "    \n",
    "        metrics = compute_metrics(y_test, y_pred)\n",
    "        pd_metrics = pd.concat([pd_metrics, metrics])\n",
    "        \n",
    "        prob = compute_cond_proba(y_test, y_pred, A_test, positive_target)\n",
    "        pd_prob = pd.concat([pd_prob, prob])\n",
    "        \n",
    "        tprs_unprotected.append(prep_roc_curve(pp_estimator, X_test, A_test, y_test, base_fpr, sensitive=True))\n",
    "        tprs_protected.append(prep_roc_curve(pp_estimator, X_test, A_test, y_test, base_fpr, sensitive=False))\n",
    "        \n",
    "    print(\"Accuracy:\", pd_metrics[\"Accuracy\"].mean())\n",
    "    print(\"F1-score:\", pd_metrics[\"F1-score\"].mean()) \n",
    "    print(\"Precision score:\", pd_metrics[\"Precision\"].mean())\n",
    "    print(\"Recall score:\", pd_metrics[\"Recall\"].mean())\n",
    "    print(\"--------------------------------------\")\n",
    "    print(\"Demographic parity: \")\n",
    "    print(\"p_yhat1_given_g1:\", pd_prob[\"p_g1\"].mean())\n",
    "    print(\"p_yhat1_given_g0:\", pd_prob[\"p_g0\"].mean())\n",
    "    print(\"p% score:\", pd_prob[\"p_percent\"].mean())\n",
    "    print(\"-------------------\")\n",
    "    print(\"Equal opportunity: \")    \n",
    "    print(\"p_yhat1_given_y1_g1:\", pd_prob[\"p_y1_g1\"].mean())\n",
    "    print(\"p_yhat1_given_y1_g0:\", pd_prob[\"p_y1_g0\"].mean())\n",
    "    print(\"Equal opportunity score:\", pd_prob[\"eq_opp_score\"].mean())\n",
    "\n",
    "#     CI    \n",
    "#     std = tprs.std(axis=0)\n",
    "#     tprs_upper = np.minimum(mean_tprs + std, 1)\n",
    "#     tprs_lower = mean_tprs - std\n",
    "    tprs_unprotected = np.array(tprs_unprotected)\n",
    "    tprs_protected= np.array(tprs_protected)\n",
    "    mean_tprs_unprotected  = tprs_unprotected.mean(axis=0)\n",
    "    mean_tprs_protected  = tprs_protected.mean(axis=0)\n",
    "\n",
    "    plt.plot(base_fpr, mean_tprs_unprotected, label='gender=0', color='b')\n",
    "    plt.plot(base_fpr, mean_tprs_protected, label='gender=1', color='g')\n",
    "#    plt.fill_between(base_fpr, tprs_lower, tprs_upper, color='grey', alpha=0.3)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([-0.01, 1.01])\n",
    "    plt.ylim([-0.01, 1.01])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.axes().set_aspect('equal', 'datalim')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7171333333333334\n",
      "F1-score: 0.7059367256074836\n",
      "Precision score: 0.7585280584768108\n",
      "Recall score: 0.7184620373529788\n",
      "--------------------------------------\n",
      "Demographic parity: \n",
      "p_yhat1_given_g1: 0.30108942183870024\n",
      "p_yhat1_given_g0: 0.3048282723272057\n",
      "p% score: 0.8959402829349912\n",
      "-------------------\n",
      "Equal opportunity: \n",
      "p_yhat1_given_y1_g1: 0.390102495935766\n",
      "p_yhat1_given_y1_g0: 0.7534130784767687\n",
      "Equal opportunity score: 0.5193536675196418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-94-330271987f23>:100: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.axes().set_aspect('equal', 'datalim')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_fairer_clf(jobs, constraint=\"demographic_parity\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this post-processing technique, the demographic parity between genders hold. We are loosing in accuracy but we could be happy to see that, with perfect equality between $\\hat{P}(\\hat{Y}=1 | G=1))$ and $\\hat{P}(\\hat{Y}=1 | G=0))$, the accuracy seems still pretty good. However, we still loose about 16% in accuracy and equal opportunity has been deteriorated. The model seems to perform quite poorly.\n",
    "\n",
    "Surprisingly, after performing the post-processing algorithm, $\\hat{P}(\\hat{Y}=1 | Y=1, G=1)) < \\hat{P}(\\hat{Y}=1 | Y=1, G=0))$ contrary to the results of `evaluate_clf`. The constraint is certainly too strong. We repeat the post-processing strategy constraining on equal opportunity which generally matters more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7922166666666669\n",
      "F1-score: 0.792071085228283\n",
      "Precision score: 0.7926382007752427\n",
      "Recall score: 0.7925339444636111\n",
      "--------------------------------------\n",
      "Demographic parity: \n",
      "p_yhat1_given_g1: 0.6093264815412666\n",
      "p_yhat1_given_g0: 0.3984934469014203\n",
      "p% score: 0.6559188370783725\n",
      "-------------------\n",
      "Equal opportunity: \n",
      "p_yhat1_given_y1_g1: 0.7905763539801091\n",
      "p_yhat1_given_y1_g0: 0.7807953563306076\n",
      "Equal opportunity score: 0.947187983688345\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-94-330271987f23>:100: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.\n",
      "  plt.axes().set_aspect('equal', 'datalim')\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluate_fairer_clf(jobs, constraint=\"equalized_odds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results are more satisfactory as the reduction in accuracy is clearly less significant (about 6%). Equal odds hold and demographic parity is slightly positively affected, reducing the gap between genders compared to the results of `evaluate_clf`. The average ROC curves look much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10. Find a fair thresholding rule on the prediction of your classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plotted the average ROC curves for both groups and this is not easy to find a fair thresholding rule. Equality between both true positive rates and false positive rates (equalized odds) would be too strict in the first case where we are already constraining on demographic parity. But we could take a threshold such that the true positive rates of the two groups are equal.\n",
    "In the second case, as we contrained our post-processing on equalized odds, the two curves coincide already. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
